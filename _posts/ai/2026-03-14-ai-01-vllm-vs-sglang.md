---
layout: post
title: "vLLM과 SGLang 차이: 서빙 엔진 vs 제어 언어"
date: 2025-02-20 09:00:00 +0900
categories: [IT, AI]
tags: [AI, LLM, vLLM, SGLang, 서빙, 추론]
description: "vLLM은 추론 엔진, SGLang은 LLM 제어 언어라는 관점에서 차이를 정리합니다."
---

# vLLM과 SGLang 차이: 서빙 엔진 vs 제어 언어

vLLM과 SGLang은 모두 LLM 스택에서 자주 등장하지만 역할이 다릅니다.  
간단히 말하면 **vLLM은 추론 성능**, **SGLang은 추론 흐름 제어**에 집중합니다.

## 1. 한 줄 정의

- **vLLM**: GPU에서 토큰 생성 속도와 처리량을 극대화하는 **서빙 엔진**
- **SGLang**: LLM 호출 흐름을 프로그램처럼 제어하는 **제어 언어 + 런타임**

## 2. 문제 영역이 다르다

vLLM은 “어떻게 더 빠르게 생성할 것인가”가 핵심입니다.  
SGLang은 “LLM을 어떤 단계로, 어떤 조건에서 사용할 것인가”가 핵심입니다.

즉 **속도 vs 흐름 제어**가 본질입니다.

## 3. vLLM의 특징

- **PagedAttention**으로 KV 캐시를 효율적으로 관리
- **동적 배칭**으로 다수 요청을 묶어 처리량 향상
- stateless 구조: 요청 간 상태를 유지하지 않음

사용 시나리오:
- 대규모 동시 요청 처리
- 응답 속도가 최우선인 서비스

## 4. SGLang의 특징

- 조건 분기, 반복, 상태 저장 등 **프로그래밍적 흐름**
- 여러 번 LLM 호출을 조합하여 **추론 파이프라인** 구성
- tool 호출/함수 실행과의 결합이 자연스러움

사용 시나리오:
- 에이전트 워크플로우
- 다단계 추론과 의사결정

## 5. 계층 구조로 보면 더 명확하다

```
Application / Workflow
        ↑
     SGLang
        ↑
     LLM API
        ↑
      vLLM
        ↑
      GPU
```

같은 레이어가 아니라 **서로 다른 계층**입니다.

## 6. 함께 사용하는 경우

현업에서는 **SGLang으로 흐름을 제어하고 vLLM으로 추론을 가속**하는 조합이 많습니다.

예:
- SGLang에서 상태를 관리하고
- vLLM 서버에 요청을 보내 결과를 받는 구조

## 7. 선택 기준

- **빠른 추론이 필요** → vLLM
- **복잡한 워크플로우/에이전트** → SGLang
- **둘 다 필요** → 조합 사용

## 8. 요약

vLLM과 SGLang은 경쟁 관계가 아니라 **역할 분담**입니다.  
성능과 흐름 제어라는 서로 다른 문제를 해결하므로, 목적에 맞게 선택하면 됩니다.

